{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, '../functions')\n",
    "import data_utilities as data_u\n",
    "import dict_utilities as dict_u\n",
    "\n",
    "#from jupyterthemes import jtplot\n",
    "#jtplot.style()\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "data_folder = '../data/'\n",
    "dict_dir = data_folder + 'data_dict.pkl'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing dict_utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers already saved : dict_keys(['google', 'exxon', 'total'])\n",
      "Tickers after reset : dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "import dict_utilities as dict_u\n",
    "\n",
    "data_dict = dict_u.get_dict(dict_dir)\n",
    "print(f\"Tickers already saved : {data_dict.keys()}\")\n",
    "\n",
    "dict_u.reset_dict(dict_dir)\n",
    "data_dict = dict_u.get_dict(dict_dir)\n",
    "print(f\"Tickers after reset : {data_dict.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing data_utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add news to data dictionary from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers added : dict_keys(['google', 'exxon'])\n",
      "\n",
      "Number of news in ticker Google : 3608\n"
     ]
    }
   ],
   "source": [
    "import data_utilities as data_u\n",
    "\n",
    "search_words = ['Google', 'Exxon']\n",
    "news_to_read = \"Reuters\"\n",
    "format_cols = [\"Text\", \"Author\", \"Date\"]\n",
    "data_u.add_news_to_dict(search_words, data_folder, news_to_read, dict_dir, format_cols)\n",
    "data_dict = dict_u.get_dict(dict_dir)\n",
    "print(f\"Tickers added : {data_dict.keys()}\\n\")\n",
    "print(f\"Number of news in ticker {search_words[0]} : {len(data_dict[search_words[0].lower()])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add news to data dictionary from Twitter account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers before operation : dict_keys(['google', 'exxon'])\n",
      "\n",
      "Tickers now : dict_keys(['google', 'exxon', 'total'])\n",
      "\n",
      "Number of news in ticker Google : 3708\n"
     ]
    }
   ],
   "source": [
    "date_since = \"2020-11-13\"\n",
    "nb_items = 100\n",
    "language = \"fr\"\n",
    "codes = data_u.get_codes(data_folder + \"twitter_codes.txt\")\n",
    "from_ids = ['Google', 'Total']\n",
    "print(f\"Tickers before operation : {data_dict.keys()}\\n\")\n",
    "data_u.add_tweets_to_dict(date_since, nb_items, language, codes,\\\n",
    "                    format_cols, dict_dir, retweet=False, from_ids=from_ids)\n",
    "data_dict = dict_u.get_dict(dict_dir)\n",
    "print(f\"Tickers now : {data_dict.keys()}\\n\")\n",
    "print(f\"Number of news in ticker {search_words[0]} : {len(data_dict[search_words[0].lower()])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add news to data dictionary from all over Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers before operation : dict_keys(['google', 'exxon', 'total'])\n",
      "\n",
      "Tickers now : dict_keys(['google', 'exxon', 'total', 'facebook'])\n",
      "\n",
      "Number of news in ticker Google : 3808\n"
     ]
    }
   ],
   "source": [
    "date_since = \"2020-11-13\"\n",
    "nb_items = 100\n",
    "language = \"fr\"\n",
    "codes = data_u.get_codes(data_folder + \"twitter_codes.txt\")\n",
    "from_words = ['Google', 'Facebook']\n",
    "print(f\"Tickers before operation : {data_dict.keys()}\\n\")\n",
    "data_u.add_tweets_to_dict(date_since, nb_items, language, codes,\\\n",
    "                    format_cols, dict_dir, retweet=False, from_words=from_words)\n",
    "data_dict = dict_u.get_dict(dict_dir)\n",
    "print(f\"Tickers now : {data_dict.keys()}\\n\")\n",
    "print(f\"Number of news in ticker {search_words[0]} : {len(data_dict[search_words[0].lower()])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing nlp_utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the dataframe of a company into BOW (with TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document - words matrix: (4020, 12978)\n",
      "First words: ['aa', 'aal', 'aba', 'aback', 'abacus', 'abandon', 'abandoned', 'abandonment', 'abate', 'abb', 'abbey', 'abbreviate', 'abdominal', 'abide', 'abiding', 'ability', 'able', 'ably', 'aboard', 'aborted', 'abortion', 'abortive', 'abound', 'abrasive', 'abroad', 'abrupt', 'abruptly', 'absence', 'absent', 'absentee', 'absolute', 'absolutely', 'absorb', 'absorbed', 'absorbing', 'absorption', 'abstain', 'abstract', 'abstractly', 'absurd', 'abu', 'abundance', 'abundant', 'abundantly', 'abuse', 'abuser', 'abusive', 'abuzz', 'abysmal', 'abyss', 'academic', 'academy', 'acca', 'accelerate', 'accelerated', 'acceleration', 'accelerator', 'accelerometer', 'accent', 'accept', 'acceptable', 'acceptance', 'accepted', 'access', 'accessible', 'accession', 'accessory', 'accident', 'accidental', 'accidentally', 'acclaim', 'accommodate', 'accommodating', 'accommodation', 'accommodative', 'accompany', 'accomplish', 'accomplished', 'accord', 'accordance', 'according', 'accordingly', 'accordion', 'account', 'accountability', 'accountable', 'accountancy', 'accountant', 'accounting', 'accredited', 'accretive', 'accrual', 'accrue', 'accumulate', 'accumulation', 'accuracy', 'accurate', 'accurately', 'accusation', 'accuse']\n"
     ]
    }
   ],
   "source": [
    "import nlp_utilities as nlp_u\n",
    "\n",
    "data_dict = dict_u.get_dict(dict_dir)\n",
    "df = data_dict['google']\n",
    "\n",
    "bow, countvect, feat2word = nlp_u.df_to_bow(df, TFIDF=True)\n",
    "\n",
    "print(\"Document - words matrix:\", bow.shape)\n",
    "print(\"First words:\", countvect.get_feature_names()[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the dataframe of a company into Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('low', 0.7797523140907288),\n",
       " ('hit', 0.7690551280975342),\n",
       " ('record', 0.654312789440155),\n",
       " ('highest', 0.6522954106330872),\n",
       " ('galloping', 0.6289225220680237),\n",
       " ('bullion', 0.6248561143875122),\n",
       " ('mid', 0.615885317325592),\n",
       " ('gold', 0.604141116142273),\n",
       " ('heavy', 0.6038429737091064),\n",
       " ('level', 0.603442907333374)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nlp_u.df_to_vec(df)\n",
    "model.wv.most_similar(positive=\"high\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
